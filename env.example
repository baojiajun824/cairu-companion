# =============================================================================
# cAIru Base Station Environment Configuration
# =============================================================================
# Copy this file to .env and adjust values for your environment

# -----------------------------------------------------------------------------
# General
# -----------------------------------------------------------------------------
ENVIRONMENT=development
LOG_LEVEL=INFO

# -----------------------------------------------------------------------------
# Redis
# -----------------------------------------------------------------------------
REDIS_URL=redis://localhost:6379

# -----------------------------------------------------------------------------
# LLM Configuration
# -----------------------------------------------------------------------------
# Backend: "ollama" (local) or "openai" (cloud fallback)
LLM_BACKEND=ollama
OLLAMA_URL=http://localhost:11434
LLM_MODEL=phi3:mini

# Optional: OpenAI for cloud fallback (not used in Alpha local-first mode)
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-4o-mini

# -----------------------------------------------------------------------------
# ASR Configuration
# -----------------------------------------------------------------------------
# Whisper model size: tiny.en, base.en, small.en, medium.en
# Smaller = faster but less accurate
WHISPER_MODEL=small.en

# -----------------------------------------------------------------------------
# TTS Configuration
# -----------------------------------------------------------------------------
# Piper voice: see https://rhasspy.github.io/piper-samples/
PIPER_VOICE=en_US-lessac-medium

# -----------------------------------------------------------------------------
# Database
# -----------------------------------------------------------------------------
DATABASE_PATH=/app/data/cairu.db

# -----------------------------------------------------------------------------
# Gateway
# -----------------------------------------------------------------------------
GATEWAY_HOST=0.0.0.0
GATEWAY_PORT=8080

# -----------------------------------------------------------------------------
# Dashboard API
# -----------------------------------------------------------------------------
DASHBOARD_API_HOST=0.0.0.0
DASHBOARD_API_PORT=8081

# -----------------------------------------------------------------------------
# Observability
# -----------------------------------------------------------------------------
# OpenTelemetry collector endpoint (optional)
# OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317

# Prometheus metrics port (exposed by each service)
METRICS_PORT=9100

# -----------------------------------------------------------------------------
# Feature Flags
# -----------------------------------------------------------------------------
# Enable cloud fallback when local LLM fails
ENABLE_CLOUD_FALLBACK=false

# Enable proactive rule engine
ENABLE_PROACTIVE_RULES=true

# Enable caregiver event emission
ENABLE_EVENTS=true

