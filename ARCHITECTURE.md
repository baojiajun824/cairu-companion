# cAIru Base Station Architecture

## Overview

cAIru is a voice-based wellness companion for seniors with dementia. The system consists of two physical components:

1. **Companion** â€” A portable "owl" device with mic, speaker, and small display (out of scope for Alpha)
2. **Base Station** â€” Intel N100 mini-PC running the core intelligence pipeline

This document describes the Base Station architecture for the Alpha build.

---

## System Goals

| Goal | Description |
|------|-------------|
| **Local-First** | All functionality runs without internet |
| **Low Latency** | Target <1s, realistic ~5-8s on N100 |
| **Simple** | Single device, single user, minimal complexity |
| **Observable** | Comprehensive logging and metrics |

---

## High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CLIENT (Mac/iPhone/Companion)                        â”‚
â”‚                              (mic, speaker)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â”‚ Audio Stream (WebSocket over WiFi)
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                               BASE STATION (N100)                            â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                         GATEWAY SERVICE                               â”‚   â”‚
â”‚  â”‚                   (WebSocket at ws://IP:8080/ws)                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                      â”‚                                       â”‚
â”‚                                      â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                         REDIS STREAMS                                 â”‚   â”‚
â”‚  â”‚                     (message bus between services)                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚              â”‚              â”‚              â”‚              â”‚        â”‚
â”‚         â–¼              â–¼              â–¼              â–¼              â–¼        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   VAD    â”‚ â†’ â”‚   ASR    â”‚ â†’ â”‚ ORCHESTRATOR â”‚ â†’ â”‚   LLM    â”‚ â†’ â”‚  TTS   â”‚ â”‚
â”‚  â”‚  Silero  â”‚   â”‚ Whisper  â”‚   â”‚    State     â”‚   â”‚  Ollama  â”‚   â”‚ Piper  â”‚ â”‚
â”‚  â”‚ (10ms)   â”‚   â”‚ (1000ms) â”‚   â”‚   (50ms)     â”‚   â”‚ (3-6s)   â”‚   â”‚(300ms) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                         DATA STORES                                   â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚   SQLite (conversations, profiles)    Ollama (LLM models)            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Pipeline Flow

### Reactive Flow (User Speaks)

```
1. Client streams audio continuously to Gateway via WebSocket
2. Gateway â†’ VAD: Voice activity detection (server-side)
3. VAD detects speech boundaries (start/end of utterance)
4. If complete utterance detected:
   a. VAD â†’ ASR: Transcribe speech to text
   b. ASR â†’ Orchestrator: Build context + prompt
   c. Orchestrator â†’ LLM: Generate response (streaming)
   d. LLM â†’ TTS: Each sentence streamed individually
   e. TTS â†’ Gateway: Audio for each sentence
   f. Gateway â†’ Client: Playback (sentence by sentence)
```

### Key Optimization: Sentence Streaming

Instead of waiting for the full LLM response, we:
1. Stream LLM output token-by-token
2. Detect sentence boundaries (., !, ?)
3. Send each complete sentence to TTS immediately
4. Client plays first sentence while LLM generates the rest

This reduces perceived latency from ~8s to ~5s.

---

## Service Descriptions

### Gateway Service
- **Purpose**: Entry point for client devices
- **Protocol**: WebSocket at `/ws`
- **Responsibilities**:
  - Accept WebSocket connections
  - Handle both binary audio and JSON-wrapped base64 audio
  - Route responses back to clients
  - Health check at `/health`

### VAD Service (Voice Activity Detection)
- **Purpose**: Detect when user starts/stops speaking
- **Model**: Silero VAD (with energy-based fallback)
- **Responsibilities**:
  - Server-side speech boundary detection
  - Accumulate audio until utterance complete
  - Only forward complete utterances to ASR

### ASR Service (Automatic Speech Recognition)
- **Purpose**: Convert speech to text
- **Model**: Faster-Whisper `tiny.en` (~1s latency)
- **Responsibilities**:
  - Transcribe audio segments
  - Output text with confidence scores

### Orchestrator Service
- **Purpose**: Central brain of the system
- **Responsibilities**:
  - Conversation state management (SQLite)
  - User profile and memory
  - Build LLM prompts with context
  - Enforce response brevity

### LLM Service
- **Purpose**: Natural language generation
- **Model**: Ollama with `qwen2:0.5b` (fastest for CPU)
- **Responsibilities**:
  - Generate conversational responses
  - **Streaming**: Output sentences as they complete
  - Send each sentence directly to TTS

### TTS Service (Text-to-Speech)
- **Purpose**: Convert text to natural speech
- **Model**: Piper TTS `en_US-lessac-low`
- **Responsibilities**:
  - Synthesize audio for each sentence
  - Return audio to Gateway for playback

---

## Technology Stack

| Component | Technology | Rationale |
|-----------|------------|-----------|
| **Language** | Python 3.11+ | Fast iteration, rich ML ecosystem |
| **Framework** | FastAPI | Async, WebSocket support |
| **Message Bus** | Redis Streams | Lightweight, persistent |
| **Database** | SQLite | Simple, local, no dependencies |
| **Containers** | Docker Compose | Isolation, reproducibility |
| **ASR** | Faster-Whisper tiny.en | Fastest for CPU |
| **LLM** | Ollama qwen2:0.5b | Smallest capable model |
| **TTS** | Piper lessac-low | Fast CPU inference |
| **VAD** | Silero VAD | Tiny, fast |

---

## Latency Analysis

### Measured on N100 (CPU-only)

| Stage | Latency | Notes |
|-------|---------|-------|
| Network (WiFi) | ~5ms | Local network, negligible |
| VAD | ~50ms | Energy-based detection |
| ASR | ~800-1200ms | Whisper tiny.en |
| Orchestrator | ~50ms | SQLite + prompt build |
| LLM (first sentence) | ~3-6s | qwen2:0.5b streaming |
| TTS | ~200-400ms | Piper low voice |
| **Total to first audio** | **~5-8s** | |

### Bottleneck Analysis

```
LLM inference: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 70%
ASR:           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 20%
TTS:           â–ˆâ–ˆâ–ˆ 7%
Other:         â–ˆ 3%
```

**The LLM is the bottleneck.** Improving it requires:
- GPU acceleration (not available on N100)
- Cloud API fallback (adds latency, requires internet)
- Better local models (as they become available)

---

## Data Storage (SQLite)

```sql
-- User profile (single user for Alpha)
user_profiles: user_id, name, preferred_name, life_details, preferences

-- Conversation history
conversation_turns: session_id, role, content, timestamp

-- Care plan
care_plans: user_id, medications, routines, contacts

-- Learned facts (memory)
learned_facts: user_id, fact_type, fact_key, fact_value
```

Database location: `/app/data/cairu.db` (inside orchestrator container)

---

## Message Bus Topics (Redis Streams)

| Stream | Publisher | Consumer | Data |
|--------|-----------|----------|------|
| `cairu:audio:inbound` | Gateway | VAD | Raw audio chunks |
| `cairu:audio:segments` | VAD | ASR | Complete utterances |
| `cairu:text:transcripts` | ASR | Orchestrator | Transcribed text |
| `cairu:llm:requests` | Orchestrator | LLM | Prompt + context |
| `cairu:llm:responses` | LLM | Orchestrator | Full response |
| `cairu:tts:requests` | LLM | TTS | Each sentence |
| `cairu:audio:outbound` | TTS | Gateway | Audio + text |

---

## Configuration

### Models (in `shared/cairu_common/config.py`)

| Setting | Value | Notes |
|---------|-------|-------|
| `whisper_model` | `tiny.en` | Fastest ASR |
| `llm_model` | `qwen2:0.5b` | Fastest LLM for CPU |
| `piper_voice` | `en_US-lessac-low` | Fast TTS voice |

### Environment Variables

Set in `docker-compose.yml`:

| Variable | Default | Description |
|----------|---------|-------------|
| `REDIS_URL` | `redis://redis:6379` | Redis connection |
| `OLLAMA_URL` | `http://ollama:11434` | Ollama API |
| `LOG_LEVEL` | `INFO` | Logging verbosity |

---

## Network Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         WiFi           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  N100 Base      â”‚
â”‚   (Mac)     â”‚    ws://IP:8080/ws      â”‚  Station        â”‚
â”‚             â”‚                         â”‚                 â”‚
â”‚   ðŸŽ¤ Mic    â”‚    ~5ms latency         â”‚   Docker        â”‚
â”‚   ðŸ”Š Speakerâ”‚    (local network)      â”‚   Containers    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why WiFi over Bluetooth?**
- WiFi: 1-5ms latency
- Bluetooth: 40-200ms latency (codec overhead)
- WiFi supports full duplex, higher bandwidth

---

## Project Structure

```
cairu-companion/
â”œâ”€â”€ docker-compose.yml          # Service orchestration
â”œâ”€â”€ Makefile                    # Common commands
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ gateway/               # WebSocket entry point
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ main.py        # FastAPI app
â”‚   â”‚       â”œâ”€â”€ websocket.py   # Connection manager
â”‚   â”‚       â””â”€â”€ routing.py     # Audio routing
â”‚   â”‚
â”‚   â”œâ”€â”€ vad/                   # Voice Activity Detection
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ main.py        # Service entry
â”‚   â”‚       â””â”€â”€ detector.py    # Silero VAD wrapper
â”‚   â”‚
â”‚   â”œâ”€â”€ asr/                   # Speech Recognition
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ main.py        # Service entry
â”‚   â”‚       â””â”€â”€ transcriber.py # Whisper wrapper
â”‚   â”‚
â”‚   â”œâ”€â”€ orchestrator/          # Central brain
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ main.py        # Service entry
â”‚   â”‚       â”œâ”€â”€ state.py       # SQLite state manager
â”‚   â”‚       â””â”€â”€ prompts/       # LLM prompt templates
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/                   # Language model
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ main.py        # Service entry
â”‚   â”‚       â”œâ”€â”€ router.py      # Model selection
â”‚   â”‚       â””â”€â”€ backends/      # Ollama backend
â”‚   â”‚
â”‚   â””â”€â”€ tts/                   # Text-to-Speech
â”‚       â””â”€â”€ src/
â”‚           â”œâ”€â”€ main.py        # Service entry
â”‚           â””â”€â”€ synthesizer.py # Piper wrapper
â”‚
â”œâ”€â”€ shared/
â”‚   â””â”€â”€ cairu_common/          # Shared library
â”‚       â”œâ”€â”€ config.py          # Centralized config
â”‚       â”œâ”€â”€ models.py          # Pydantic models
â”‚       â”œâ”€â”€ redis_client.py    # Redis wrapper
â”‚       â””â”€â”€ logging.py         # Structured logging
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ test_streaming.py      # Voice test client
â”‚
â””â”€â”€ config/
    â””â”€â”€ rules/                 # Proactive rule definitions
```

---

## Simplifications for Alpha

| Area | Simplification |
|------|----------------|
| **Devices** | Single device, no registration |
| **Users** | Single user, no auth |
| **Dashboard** | Not implemented |
| **Events** | Not implemented |
| **Cloud** | No cloud fallback |

---

## Future Considerations (Post-Alpha)

1. **GPU Acceleration**: Add support for Intel Arc GPU or external GPU
2. **Cloud Fallback**: Use OpenAI/Claude API when local LLM struggles
3. **Multi-device**: Support multiple companions per base station
4. **Caregiver Dashboard**: Web UI for care plan management
5. **Mobile App**: iOS/Android client for family members
6. **Wake Word**: "Hey Cairu" activation

---

*Last Updated: January 2026*
